{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1021c15a",
      "metadata": {
        "id": "1021c15a",
        "outputId": "808ef04e-c2c8-416a-bfc5-0fda5be50ec2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\tntnt\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Importing important libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "#NLTK-------------------------------\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "\n",
        "# Import libraries for feature \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d095d51f",
      "metadata": {
        "id": "d095d51f",
        "outputId": "9bd790ff-7362-4ea5-bf1a-9076d482b6c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 2)\n",
            "(2070, 17)\n"
          ]
        }
      ],
      "source": [
        "#Read files\n",
        "textfile = r'C:\\Users\\tntnt\\Downloads\\Comments (1).csv'\n",
        "textData = pd.read_csv(textfile) #creates a dataframe\n",
        "\n",
        "CustInfofile = r'C:\\Users\\tntnt\\Downloads\\Customers (1).csv'\n",
        "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
        "\n",
        "print(textData.shape)\n",
        "print(CustInfoData.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49d6c62",
      "metadata": {
        "id": "f49d6c62",
        "outputId": "556203db-2a36-4e94-c796-5a47f68131e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 16)\n",
            "   ID Sex Status  Children  Est_Income Car_Owner   Usage        Age  RatePlan  \\\n",
            "0   1   F      S         1    38000.00         N  229.64  24.393333         3   \n",
            "1   6   M      M         2    29616.00         N   75.29  49.426667         2   \n",
            "2   8   M      M         0    19732.80         N   47.25  50.673333         3   \n",
            "3  11   M      S         2       96.33         N   59.01  56.473333         1   \n",
            "4  14   F      M         2    52004.80         N   28.14  25.140000         1   \n",
            "\n",
            "   LongDistance  International   Local  Dropped Paymethod LocalBilltype  \\\n",
            "0         23.56            0.0  206.08        0        CC        Budget   \n",
            "1         29.78            0.0   45.50        0        CH     FreeLocal   \n",
            "2         24.81            0.0   22.44        0        CC     FreeLocal   \n",
            "3         26.13            0.0   32.88        1        CC        Budget   \n",
            "4          5.03            0.0   23.11        0        CH        Budget   \n",
            "\n",
            "  LongDistanceBilltype  \n",
            "0       Intnl_discount  \n",
            "1             Standard  \n",
            "2             Standard  \n",
            "3             Standard  \n",
            "4       Intnl_discount  \n",
            "(2070, 2)\n",
            "     ID                                           Comments\n",
            "0  1309  Does not like the way the phone works. It is t...\n",
            "1  3556  Wanted to know the nearest store location. Wan...\n",
            "2  2230  Wants to know how to do text messaging. Referr...\n",
            "3  2312  Asked how to disable call waiting. referred hi...\n",
            "4  3327  Needs help learning how to use the phone. I su...\n",
            "0       Cancelled\n",
            "1         Current\n",
            "2         Current\n",
            "3         Current\n",
            "4       Cancelled\n",
            "          ...    \n",
            "2065    Cancelled\n",
            "2066    Cancelled\n",
            "2067    Cancelled\n",
            "2068    Cancelled\n",
            "2069    Cancelled\n",
            "Name: TARGET, Length: 2070, dtype: object\n"
          ]
        }
      ],
      "source": [
        "#Extract target column from Customer Info file\n",
        "y_train = CustInfoData[\"TARGET\"]\n",
        "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
        "                     \n",
        "print(X_train.shape)\n",
        "print(X_train.head())\n",
        "print(textData.shape)\n",
        "print(textData.head())\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5853e90",
      "metadata": {
        "id": "a5853e90"
      },
      "outputs": [],
      "source": [
        "#Tokenize - Split the sentences to lists of words\n",
        "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n",
        "\n",
        "export_csv = textData.to_csv(r'C:\\Users\\tntnt\\Downloads\\TextDataTokenized.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b6b0bb",
      "metadata": {
        "id": "57b6b0bb"
      },
      "outputs": [],
      "source": [
        "# Use English stemmer.\n",
        "#Snowball stemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData.to_csv(r'C:\\Users\\tntnt\\Downloads\\Stemmer.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e75d150",
      "metadata": {
        "id": "3e75d150"
      },
      "outputs": [],
      "source": [
        "# Use English stemmer to find the words that are original\n",
        "#Porter stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData.to_csv(r'C:\\Users\\tntnt\\Downloads\\Porter.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dec8320",
      "metadata": {
        "id": "0dec8320"
      },
      "outputs": [],
      "source": [
        "# Use English stemmer.\n",
        "#Lancaster stemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData.to_csv(r'C:\\Users\\tntnt\\Downloads\\Lancaster.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc0bdf1",
      "metadata": {
        "id": "bbc0bdf1"
      },
      "outputs": [],
      "source": [
        "#Join stemmed strings and exported the files\n",
        "newTextData['CommentsTokenizedStemmed'] = newTextData['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "export_csv = newTextData.to_csv(r'C:\\Users\\tntnt\\Downloads\\NewTextDataJoined.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ed9726d",
      "metadata": {
        "id": "3ed9726d",
        "outputId": "226437f4-3c3a-4d66-b73c-9501e1b14d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 364)\n"
          ]
        }
      ],
      "source": [
        "#Done Bag-Of-Words model  \n",
        "#Done Term Document Matrix by eliminating the stop words\n",
        "#Learn the vocabulary dictionary and return term-document matrix.\n",
        "#count_vect = CountVectorizer(stop_words=None)\n",
        "count_vect = CountVectorizer(stop_words='english',lowercase=False)\n",
        "TD_counts = count_vect.fit_transform(newTextData.CommentsTokenizedStemmed)\n",
        "print(TD_counts.shape)\n",
        "#print(TD_counts.dtype)\n",
        "#print(count_vect.get_feature_names())\n",
        "#print(TD_counts)\n",
        "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
        "#print(DF_TD_Counts)\n",
        "export_csv = DF_TD_Counts.to_csv(r'C:\\Users\\tntnt\\Downloads\\TD-counts-TokenizedStemmed.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efcd1dd3",
      "metadata": {
        "id": "efcd1dd3",
        "outputId": "ad17261d-2e99-4e56-a8f0-acfc07316266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 364)\n"
          ]
        }
      ],
      "source": [
        "#Computing TF-IDF Matrix to assign numerical  to the data\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(TD_counts)\n",
        "print(X_train_tfidf.shape)\n",
        "DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray())\n",
        "\n",
        "export_csv= DF_TF_IDF.to_csv(r'C:\\Users\\tntnt\\Downloads\\TFIDF-counts-TokenizedStemmed.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d67cce",
      "metadata": {
        "id": "87d67cce",
        "outputId": "f71ddfe1-8886-47f7-d047-ba19146c6bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 380)\n"
          ]
        }
      ],
      "source": [
        "#merge files - filter type\n",
        "DF_TF_IDF['ID'] = textData['ID']\n",
        "combined = pd.merge(X_train, DF_TF_IDF, on ='ID')\n",
        "print(combined.shape)\n",
        "combined.head()\n",
        "export_csv= combined.to_csv(r'C:\\Users\\tntnt\\Downloads\\combined.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38343151",
      "metadata": {
        "id": "38343151",
        "outputId": "c2b8b900-b8a8-4e2b-9589-0979d52352af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
            "(2070, 388)\n"
          ]
        }
      ],
      "source": [
        "#Do one Hot encoding for categorical features - filter type\n",
        "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
        "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
        "print(X_cat)\n",
        "combined_one_hot = pd.get_dummies(combined,columns=X_cat)\n",
        "print(combined_one_hot.shape)\n",
        "export_csv= combined_one_hot.to_csv(r'C:\\Users\\tntnt\\Downloads\\OneHotEncoding.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0cf6521",
      "metadata": {
        "id": "e0cf6521",
        "outputId": "0993f1fc-fa1a-4395-e3eb-7110a66e111d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 25)\n",
            "[ 15  49  61  69  79 101 115 118 121 175 187 191 206 214 216 221 226 248\n",
            " 249 260 272 304 313 319 326]\n"
          ]
        }
      ],
      "source": [
        "#Feature selection - using filter method\n",
        "#Suppose, we select 50 features with top 50 Fisher scores\n",
        "selector = SelectKBest(k=25) #doing for 25 best features\n",
        "#selector = SelectKBest(score_func=chi2, k=25)\n",
        "\n",
        "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
        "new_DF_TF_IDF = selector.fit_transform(DF_TF_IDF,y_train)\n",
        "print(new_DF_TF_IDF.shape)\n",
        "\n",
        "feature_names_out = selector.get_support(indices=True)\n",
        "print(feature_names_out)\n",
        "\n",
        "DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF)\n",
        "#print(DF_TF_IDF_SelectedFeatures)\n",
        "\n",
        "export_csv= DF_TF_IDF_SelectedFeatures.to_csv(r'C:\\Users\\tntnt\\Downloads\\TFIDF-25.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76def11",
      "metadata": {
        "id": "d76def11",
        "outputId": "797eb76d-5b9b-495a-e17e-0815c24a650f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 50)\n",
            "[  0  15  17  36  48  49  61  63  69  71  79  97 101 109 115 118 121 130\n",
            " 141 148 160 161 175 187 191 196 206 214 216 221 225 226 237 244 248 249\n",
            " 254 260 265 272 304 313 318 319 321 326 330 332 342 359]\n"
          ]
        }
      ],
      "source": [
        "#Feature selection - filter type\n",
        "#Suppose, we select 50 features with top 50 Fisher scores\n",
        "selector = SelectKBest(k=50)\n",
        "#selector = SelectKBest(score_func=chi2, k=25)\n",
        "\n",
        "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
        "new_DF_TF_IDF = selector.fit_transform(DF_TF_IDF,y_train)\n",
        "print(new_DF_TF_IDF.shape)\n",
        "\n",
        "feature_names_out = selector.get_support(indices=True)\n",
        "print(feature_names_out)\n",
        "\n",
        "DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF)\n",
        "#print(DF_TF_IDF_SelectedFeatures)\n",
        "\n",
        "export_csv= DF_TF_IDF_SelectedFeatures.to_csv(r'C:\\Users\\tntnt\\Downloads\\TFIDF-50.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36de1555",
      "metadata": {
        "id": "36de1555",
        "outputId": "cfe49152-f9f5-4d01-d2d1-3491ec2ed22f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 75)\n",
            "[  0  15  17  20  36  48  49  50  61  63  69  71  72  76  79  86  97 101\n",
            " 108 109 115 118 120 121 126 130 141 148 159 160 161 171 175 187 191 195\n",
            " 196 206 214 216 221 225 226 237 240 244 245 248 249 254 256 260 263 265\n",
            " 271 272 273 277 278 287 298 304 313 318 319 321 324 326 330 332 337 342\n",
            " 350 359 361]\n"
          ]
        }
      ],
      "source": [
        "#Feature selection - filter type\n",
        "#Suppose, we select 50 features with top 50 Fisher scores\n",
        "selector = SelectKBest(k=75)\n",
        "#selector = SelectKBest(score_func=chi2, k=75)\n",
        "\n",
        "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
        "new_DF_TF_IDF = selector.fit_transform(DF_TF_IDF,y_train)\n",
        "print(new_DF_TF_IDF.shape)\n",
        "\n",
        "feature_names_out = selector.get_support(indices=True)\n",
        "print(feature_names_out)\n",
        "\n",
        "DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF)\n",
        "#print(DF_TF_IDF_SelectedFeatures)\n",
        "\n",
        "export_csv= DF_TF_IDF_SelectedFeatures.to_csv(r'C:\\Users\\tntnt\\Downloads\\TFIDF-75.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd8b0070",
      "metadata": {
        "id": "fd8b0070",
        "outputId": "679366d5-6412-4ab0-9fa1-a2fba901b4ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2070, 10)\n",
            "[ 15  69 121 187 214 221 249 272 319 326]\n"
          ]
        }
      ],
      "source": [
        "#Feature selection - filter type\n",
        "#Suppose, we select 50 features with top 50 Fisher scores\n",
        "selector = SelectKBest(k=10)\n",
        "#selector = SelectKBest(score_func=chi2, k=75)\n",
        "\n",
        "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
        "new_DF_TF_IDF = selector.fit_transform(DF_TF_IDF,y_train)\n",
        "print(new_DF_TF_IDF.shape)\n",
        "\n",
        "feature_names_out = selector.get_support(indices=True)\n",
        "print(feature_names_out)\n",
        "\n",
        "DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF)\n",
        "#print(DF_TF_IDF_SelectedFeatures)\n",
        "\n",
        "export_csv= DF_TF_IDF_SelectedFeatures.to_csv(r'C:\\Users\\tntnt\\Downloads\\TFIDF-10.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57994c16",
      "metadata": {
        "id": "57994c16",
        "outputId": "f4250be1-b682-4635-dbb5-f376603923ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       0         1          2      3     4       5         6    7         8   \\\n",
            "0     1.0  38000.00  24.393333  23.56  0.00  206.08  0.000000  0.0  0.000000   \n",
            "1     2.0  29616.00  49.426667  29.78  0.00   45.50  0.000000  0.0  0.241722   \n",
            "2     0.0  19732.80  50.673333  24.81  0.00   22.44  0.000000  0.0  0.241722   \n",
            "3     2.0     96.33  56.473333  26.13  0.00   32.88  0.000000  0.0  0.241722   \n",
            "4     2.0  52004.80  25.140000   5.03  0.00   23.11  0.000000  0.0  0.241722   \n",
            "...   ...       ...        ...    ...   ...     ...       ...  ...       ...   \n",
            "2065  0.0  78851.30  48.373333   0.37  0.00   28.66  0.387706  0.0  0.219662   \n",
            "2066  1.0  17540.70  62.786667  22.17  0.57   13.45  0.387706  0.0  0.219662   \n",
            "2067  0.0  83891.90  61.020000  28.92  0.00   45.47  0.387706  0.0  0.219662   \n",
            "2068  2.0  28220.80  38.766667  26.49  0.00   12.46  0.387706  0.0  0.219662   \n",
            "2069  0.0  28589.10  15.600000  13.19  0.00   87.09  0.387706  0.0  0.219662   \n",
            "\n",
            "            9         10   11   12        13   14   15   16   17  \n",
            "0     0.000000  0.000000  0.0  0.0  0.000000  0.0  0.0  1.0  0.0  \n",
            "1     0.000000  0.269428  0.0  0.0  0.000000  1.0  1.0  0.0  0.0  \n",
            "2     0.000000  0.269428  0.0  0.0  0.000000  1.0  1.0  0.0  0.0  \n",
            "3     0.000000  0.269428  0.0  0.0  0.000000  1.0  0.0  1.0  0.0  \n",
            "4     0.000000  0.269428  0.0  0.0  0.000000  0.0  1.0  0.0  0.0  \n",
            "...        ...       ...  ...  ...       ...  ...  ...  ...  ...  \n",
            "2065  0.376954  0.000000  0.0  0.0  0.178496  0.0  0.0  1.0  0.0  \n",
            "2066  0.376954  0.000000  0.0  0.0  0.178496  0.0  0.0  1.0  1.0  \n",
            "2067  0.376954  0.000000  0.0  0.0  0.178496  0.0  1.0  0.0  0.0  \n",
            "2068  0.376954  0.000000  0.0  0.0  0.178496  0.0  1.0  0.0  0.0  \n",
            "2069  0.376954  0.000000  0.0  0.0  0.178496  0.0  0.0  1.0  0.0  \n",
            "\n",
            "[2070 rows x 18 columns]\n",
            "(2070, 18)\n",
            "    0         1          2      3    4       5    6    7         8    9   \\\n",
            "0  1.0  38000.00  24.393333  23.56  0.0  206.08  0.0  0.0  0.000000  0.0   \n",
            "1  2.0  29616.00  49.426667  29.78  0.0   45.50  0.0  0.0  0.241722  0.0   \n",
            "2  0.0  19732.80  50.673333  24.81  0.0   22.44  0.0  0.0  0.241722  0.0   \n",
            "3  2.0     96.33  56.473333  26.13  0.0   32.88  0.0  0.0  0.241722  0.0   \n",
            "4  2.0  52004.80  25.140000   5.03  0.0   23.11  0.0  0.0  0.241722  0.0   \n",
            "\n",
            "         10   11   12   13   14   15   16   17  \n",
            "0  0.000000  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
            "1  0.269428  0.0  0.0  0.0  1.0  1.0  0.0  0.0  \n",
            "2  0.269428  0.0  0.0  0.0  1.0  1.0  0.0  0.0  \n",
            "3  0.269428  0.0  0.0  0.0  1.0  0.0  1.0  0.0  \n",
            "4  0.269428  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n"
          ]
        }
      ],
      "source": [
        "#Using wrapper method \n",
        "#Do feature selection using GBM\n",
        "#clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = GradientBoostingClassifier(n_estimators=10)\n",
        "#clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(combined_one_hot,y_train)\n",
        "#print(clf.feature_importances_)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "model = SelectFromModel(clf, prefit=True, max_features=7, threshold=-np.inf)\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "X_new= model.transform(combined_one_hot)\n",
        "X_new_SelectedFeatures= pd.DataFrame(X_new)\n",
        "\n",
        "print(X_new_SelectedFeatures)\n",
        "print(X_new_SelectedFeatures.shape)\n",
        "print(X_new_SelectedFeatures.head())\n",
        "export_csv= X_new_SelectedFeatures.to_csv(r'C:\\Users\\tntnt\\Downloads\\GBM.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da17318",
      "metadata": {
        "id": "4da17318",
        "outputId": "de82a047-ffc6-453d-88ad-bc3e741340a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False  True  True False  True False  True  True  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False  True False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False  True False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False  True False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False  True False False False False False False\n",
            " False  True False False False False False False False  True False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False  True False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False  True False  True  True False False  True False False\n",
            " False False False False]\n",
            "\n",
            " cols =  [  1   2   4   6   7   8  32  51 234 266 293 301 309 349 375 377 378 381] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.get_support())\n",
        "\n",
        "#Get column names\n",
        "cols = model.get_support(indices=True) #get column indices\n",
        "print(\"\\n cols = \", cols, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb5f4e7",
      "metadata": {
        "id": "5cb5f4e7",
        "outputId": "20183e4f-8499-4684-f986-1bc9b216132a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[  35  769]\n",
            " [  10 1256]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.78      0.04      0.08       804\n",
            "     Current       0.62      0.99      0.76      1266\n",
            "\n",
            "    accuracy                           0.62      2070\n",
            "   macro avg       0.70      0.52      0.42      2070\n",
            "weighted avg       0.68      0.62      0.50      2070\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Using wrapper method for feature selection \n",
        "#Constructing Randon forest classifier\n",
        "clf=RandomForestClassifier()\n",
        "RF_text = clf.fit(DF_TF_IDF_SelectedFeatures,y_train)\n",
        "model = SelectFromModel(clf, prefit=True, max_features=20, threshold=-np.inf)\n",
        "#print(\"Accuracy score (training): {0:.6f}\".format(clf.score(DF_TF_IDF_SelectedFeatures, y_train)))\n",
        "rf_predictions = clf.predict(DF_TF_IDF_SelectedFeatures)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_train, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_train, rf_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c30677fe",
      "metadata": {
        "id": "c30677fe",
        "outputId": "ad295126-6f15-4983-e2d3-47279cbb0a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True]\n",
            "\n",
            " cols =  [0 1 2 3 4 5 6 7 8 9] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.get_support())\n",
        "\n",
        "#Get column names\n",
        "cols = model.get_support(indices=True) #get column indices\n",
        "print(\"\\n cols = \", cols, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a339968f",
      "metadata": {
        "id": "a339968f"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.DataFrame(combined_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7830ef5f",
      "metadata": {
        "id": "7830ef5f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62d9080",
      "metadata": {
        "id": "d62d9080"
      },
      "outputs": [],
      "source": [
        "Y_Train = pd.DataFrame(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155f5a99",
      "metadata": {
        "id": "155f5a99"
      },
      "outputs": [],
      "source": [
        "new_data = pd.concat([dataframe,Y_Train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8c943f2",
      "metadata": {
        "id": "e8c943f2",
        "outputId": "2735a0da-1dae-449a-fa45-4a919cca299a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1656, 388)\n",
            "(1656, 1)\n",
            "(414, 388)\n",
            "(414, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataframe, Y_Train, test_size = .20, random_state = 1)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5419e0b9",
      "metadata": {
        "id": "5419e0b9",
        "outputId": "962a2ab7-ef86-40df-d3d4-82d4c7d245f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        ID  Children  Est_Income   Usage        Age  RatePlan  LongDistance  \\\n",
            "724   1318         1    33084.30  125.05  50.313333         1         19.77   \n",
            "348    670         2     1406.05   26.72  19.306667         3         11.55   \n",
            "102    224         2    69343.30   21.91  42.166667         2          6.36   \n",
            "1080  1967         0    30000.00  265.78  23.000000         1         45.00   \n",
            "1758  3228         0    15924.20    1.46  14.460000         2          0.00   \n",
            "...    ...       ...         ...     ...        ...       ...           ...   \n",
            "264    492         1     8073.11   89.05  43.000000         2         28.70   \n",
            "1071  1955         1     3960.50   96.13  14.693333         2         29.78   \n",
            "1273  2308         1     7545.96  200.75  16.753333         1         22.39   \n",
            "1438  2620         0    78851.30   29.04  48.373333         1          0.37   \n",
            "1363  2499         2    76289.20  104.63  48.206667         3         22.20   \n",
            "\n",
            "      International   Local  Dropped  ...  Status_S  Car_Owner_N  Car_Owner_Y  \\\n",
            "724             0.0  105.28        0  ...         1            0            1   \n",
            "348             0.0   15.17        0  ...         0            0            1   \n",
            "102             0.0   15.54        0  ...         0            1            0   \n",
            "1080            0.0  262.91        0  ...         1            1            0   \n",
            "1758            0.0    1.46        0  ...         1            1            0   \n",
            "...             ...     ...      ...  ...       ...          ...          ...   \n",
            "264             0.0   60.35        0  ...         0            1            0   \n",
            "1071            0.0   66.35        0  ...         1            1            0   \n",
            "1273            0.0  178.36        0  ...         0            0            1   \n",
            "1438            0.0   28.66        0  ...         0            1            0   \n",
            "1363            0.0   82.43        0  ...         0            1            0   \n",
            "\n",
            "      Paymethod_Auto  Paymethod_CC  Paymethod_CH  LocalBilltype_Budget  \\\n",
            "724                0             0             1                     1   \n",
            "348                0             1             0                     1   \n",
            "102                0             1             0                     0   \n",
            "1080               0             1             0                     1   \n",
            "1758               0             0             1                     0   \n",
            "...              ...           ...           ...                   ...   \n",
            "264                1             0             0                     0   \n",
            "1071               1             0             0                     0   \n",
            "1273               0             1             0                     1   \n",
            "1438               0             1             0                     0   \n",
            "1363               0             1             0                     1   \n",
            "\n",
            "      LocalBilltype_FreeLocal  LongDistanceBilltype_Intnl_discount  \\\n",
            "724                         0                                    0   \n",
            "348                         0                                    0   \n",
            "102                         1                                    0   \n",
            "1080                        0                                    0   \n",
            "1758                        1                                    0   \n",
            "...                       ...                                  ...   \n",
            "264                         1                                    0   \n",
            "1071                        1                                    0   \n",
            "1273                        0                                    0   \n",
            "1438                        1                                    0   \n",
            "1363                        0                                    1   \n",
            "\n",
            "      LongDistanceBilltype_Standard  \n",
            "724                               1  \n",
            "348                               1  \n",
            "102                               1  \n",
            "1080                              1  \n",
            "1758                              1  \n",
            "...                             ...  \n",
            "264                               1  \n",
            "1071                              1  \n",
            "1273                              1  \n",
            "1438                              1  \n",
            "1363                              0  \n",
            "\n",
            "[414 rows x 388 columns]\n",
            "accuracy\n",
            "[[131  19]\n",
            " [ 32 232]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.80      0.87      0.84       150\n",
            "     Current       0.92      0.88      0.90       264\n",
            "\n",
            "    accuracy                           0.88       414\n",
            "   macro avg       0.86      0.88      0.87       414\n",
            "weighted avg       0.88      0.88      0.88       414\n",
            "\n",
            "[0.88855422 0.89425982 0.87613293 0.88519637 0.87311178]\n",
            "0.8834510246423761\n"
          ]
        }
      ],
      "source": [
        "#do feature selection\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, Y_train)\n",
        "features_df = X_test.iloc[:]\n",
        "print(features_df)\n",
        "\n",
        "rf_predict = rf.predict(features_df)\n",
        "print(\"accuracy\".format(rf.score(features_df,Y_test)))\n",
        "print(confusion_matrix(Y_test,rf_predict))\n",
        "print(classification_report(Y_test,rf_predict))\n",
        "rf_cv_score = cross_val_score(rf,X_train,Y_train, cv=5, scoring = \"accuracy\")\n",
        "print(rf_cv_score)\n",
        "print(rf_cv_score.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "939404ab",
      "metadata": {
        "id": "939404ab",
        "outputId": "dfda3d94-68d7-4151-94f8-b45d4c1d3bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1656, 388)\n",
            "(1656, 1)\n",
            "(414, 388)\n",
            "(414, 1)\n"
          ]
        }
      ],
      "source": [
        "#Doing 80 20 train test splitX_train, X_test, Y_train, Y_test = train_test_split(dataframe, Y_Train, test_size = .20, random_state = 1)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ec6f8a",
      "metadata": {
        "id": "40ec6f8a",
        "outputId": "e6591800-eb08-4882-c07c-8c7caa9a7183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        ID  Children  Est_Income   Usage        Age  RatePlan  LongDistance  \\\n",
            "724   1318         1    33084.30  125.05  50.313333         1         19.77   \n",
            "348    670         2     1406.05   26.72  19.306667         3         11.55   \n",
            "102    224         2    69343.30   21.91  42.166667         2          6.36   \n",
            "1080  1967         0    30000.00  265.78  23.000000         1         45.00   \n",
            "1758  3228         0    15924.20    1.46  14.460000         2          0.00   \n",
            "...    ...       ...         ...     ...        ...       ...           ...   \n",
            "264    492         1     8073.11   89.05  43.000000         2         28.70   \n",
            "1071  1955         1     3960.50   96.13  14.693333         2         29.78   \n",
            "1273  2308         1     7545.96  200.75  16.753333         1         22.39   \n",
            "1438  2620         0    78851.30   29.04  48.373333         1          0.37   \n",
            "1363  2499         2    76289.20  104.63  48.206667         3         22.20   \n",
            "\n",
            "      International   Local  Dropped  ...  Status_S  Car_Owner_N  Car_Owner_Y  \\\n",
            "724             0.0  105.28        0  ...         1            0            1   \n",
            "348             0.0   15.17        0  ...         0            0            1   \n",
            "102             0.0   15.54        0  ...         0            1            0   \n",
            "1080            0.0  262.91        0  ...         1            1            0   \n",
            "1758            0.0    1.46        0  ...         1            1            0   \n",
            "...             ...     ...      ...  ...       ...          ...          ...   \n",
            "264             0.0   60.35        0  ...         0            1            0   \n",
            "1071            0.0   66.35        0  ...         1            1            0   \n",
            "1273            0.0  178.36        0  ...         0            0            1   \n",
            "1438            0.0   28.66        0  ...         0            1            0   \n",
            "1363            0.0   82.43        0  ...         0            1            0   \n",
            "\n",
            "      Paymethod_Auto  Paymethod_CC  Paymethod_CH  LocalBilltype_Budget  \\\n",
            "724                0             0             1                     1   \n",
            "348                0             1             0                     1   \n",
            "102                0             1             0                     0   \n",
            "1080               0             1             0                     1   \n",
            "1758               0             0             1                     0   \n",
            "...              ...           ...           ...                   ...   \n",
            "264                1             0             0                     0   \n",
            "1071               1             0             0                     0   \n",
            "1273               0             1             0                     1   \n",
            "1438               0             1             0                     0   \n",
            "1363               0             1             0                     1   \n",
            "\n",
            "      LocalBilltype_FreeLocal  LongDistanceBilltype_Intnl_discount  \\\n",
            "724                         0                                    0   \n",
            "348                         0                                    0   \n",
            "102                         1                                    0   \n",
            "1080                        0                                    0   \n",
            "1758                        1                                    0   \n",
            "...                       ...                                  ...   \n",
            "264                         1                                    0   \n",
            "1071                        1                                    0   \n",
            "1273                        0                                    0   \n",
            "1438                        1                                    0   \n",
            "1363                        0                                    1   \n",
            "\n",
            "      LongDistanceBilltype_Standard  \n",
            "724                               1  \n",
            "348                               1  \n",
            "102                               1  \n",
            "1080                              1  \n",
            "1758                              1  \n",
            "...                             ...  \n",
            "264                               1  \n",
            "1071                              1  \n",
            "1273                              1  \n",
            "1438                              1  \n",
            "1363                              0  \n",
            "\n",
            "[414 rows x 388 columns]\n",
            "accuracy\n",
            "[[132  18]\n",
            " [ 32 232]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.80      0.88      0.84       150\n",
            "     Current       0.93      0.88      0.90       264\n",
            "\n",
            "    accuracy                           0.88       414\n",
            "   macro avg       0.87      0.88      0.87       414\n",
            "weighted avg       0.88      0.88      0.88       414\n",
            "\n",
            "[0.88253012 0.90332326 0.86706949 0.87613293 0.86102719]\n",
            "0.8780165981145125\n"
          ]
        }
      ],
      "source": [
        "#do feature selection\n",
        "gbc = GradientBoostingClassifier()\n",
        "gbc.fit(X_train, Y_train)\n",
        "features_df = X_test.iloc[:]\n",
        "print(features_df)\n",
        "\n",
        "gbc_predict = gbc.predict(features_df)\n",
        "print(\"accuracy\".format(gbc.score(features_df,Y_test)))\n",
        "print(confusion_matrix(Y_test,gbc_predict))\n",
        "print(classification_report(Y_test,gbc_predict))\n",
        "gbc_cv_score = cross_val_score(rf,X_train,Y_train, cv=5, scoring = \"accuracy\")\n",
        "print(gbc_cv_score)\n",
        "print(gbc_cv_score.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf54f72",
      "metadata": {
        "id": "6bf54f72"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}